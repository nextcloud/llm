OC.L10N.register(
    "llm",
    {
    "Formalize" : "Formaliser",
    "Rephrase the text to be more formal and polite instead of casual." : "Omformuler teksten for √• v√¶re mer formell og h√∏flig i stedet for uformell.",
    "Simplify" : "Forenkle",
    "Make the text easier to understand." : "Gj√∏r teksten lettere √• forst√•.",
    "Local Large language model" : "Lokal stor spr√•kmodell",
    "TextProcessing provider using a Large Language Model that runs locally on CPU" : "Leverand√∏r av tekstbehandling som bruker en stor spr√•kmodell som kj√∏rer lokalt p√• CPU",
    "A TextProcessing provider Large Language Model that runs locally on CPU\n\nThe models run completely on your machine. No private data leaves your servers.\n\nAfter installing this app you will need to run\n\n    occ llm:download-model\n\nModels:\n\n* Llama 2 by Meta\n  * Languages: English\n  * [LLAMA 2 Community License](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* GPT4All Falcon by Nomic AI\n  * Languages: English\n  * [Apache License 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\n* Leo HessianAI by LAION LeoLM\n  * Languages: English/German\n  * [LLAMA 2 Community License](https://download.nextcloud.com/server/apps/llm/leo-hessianai-13B-chat-bilingual-GGUF/LICENSE)\nRequirements:\n\n* x86 CPU (with support for AVX instructions)\n* GNU lib C (musl is not supported)\n* Python 3.10+  (including python-venv)\n\n#### Nextcloud All-in-One:\nWith Nextcloud AIO, this app is not going to work because AIO uses musl. However you can use [this community container](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai) as replacement for this app.\n\n## Ethical AI Rating \"Llama 2\" model\n### Rating: üü°\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the model‚Äôs performance and CO2 usage.\n\n## Ethical AI Rating for \"GPT4All Falcon\" model\n### Rating: üü¢\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n* the training data is freely available, making it possible to check or correct for bias or optimise the performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/)." : "Leverand√∏r av tekstbehandling som bruker en stor spr√•kmodell som kj√∏rer lokalt p√• CPU\n\nModellene kj√∏rer utelukkende p√• maskinen din. Ingen private data forlater serverne dine.\n\nEtter √• ha installert denne appen m√• du kj√∏re\n\n    occ llm:download-model\n\nModeller:\n\n* Llama 2 av Meta\n  * Spr√•k: English\n  * [LLAMA 2 Fellesskapslisens](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* GPT4All Falcon av Nomic AI\n  * Spr√•k: English\n  * [Apache Lisens 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\n* Leo HessianAI av LAION LeoLM\n  * Spr√•k: Engelsk/Tysk\n  * [LLAMA 2 Fellesskapslisens](https://download.nextcloud.com/server/apps/llm/leo-hessianai-13B-chat-bilingual-GGUF/LICENSE)\nKrav:\n\n* x86 CPU (med st√∏tte for AVX-instruksjoner)\n* GNU lib C (musl st√∏ttes ikke)\n* Python 3.10+  (inkludert python-venv)\n\n#### Nextcloud All-in-One:\nMed Nextcloud AIO kommer ikke denne appen til √• fungere fordi AIO bruker musl. Du kan imidlertid bruke [denne fellesskapsbeholderen](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai) som erstatning for denne appen.\n\n## Etisk AI-vurdering \"Llama 2\" modell\n### Vurdering: üü°\n\nPositivt:\n* programvaren for oppl√¶ring og slutning av denne modellen er √•pen kildekode\n* den trente modellen er fritt tilgjengelig, og kan derfor kj√∏res p√• stedet\n\nNegativt:\n\n* treningsdataene er ikke fritt tilgjengelig, noe som begrenser eksterne parters mulighet til √• kontrollere og korrigere for skjevhet eller optimalisere modellens ytelse og CO2-bruk.\n\n## Etisk AI-vurdering for \"GPT4All Falcon\" modell\n### Vurdering: üü¢\n\nPositivt:\n* programvaren for oppl√¶ring og slutning av denne modellen er √•pen kildekode\n* den trente modellen er fritt tilgjengelig, og kan derfor kj√∏res p√• stedet\n*treningsdataene er fritt tilgjengelige, noe som gj√∏r det mulig √• kontrollere eller korrigere for skjevhet eller optimere ytelsen og CO2-bruken.\n\nFinn ut mer om Nextcloud Ethical AI Rating [i bloggen v√•r](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/).",
    "Status" : "Status",
    "Machine learning model has been downloaded successfully." : "Maskinl√¶ringsmodell er lastet ned.",
    "The machine learning model still needs to be downloaded (see below)." : "Maskinl√¶ringsmodellen m√• fortsatt lastes ned (se nedenfor).",
    "Could not execute python. You may need to set the path to a working executable manually. (See below.)" : "Kunne ikke utf√∏re python. Du m√• kanskje angi banen til en fungerende kj√∏rbar manuelt. (Se nedenfor.)",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Bakgrunnsjobber utf√∏res ikke via cron. Denne appen krever at bakgrunnsjobber utf√∏res via cron.",
    "The app was installed successfully and will run prompts in background processes on request." : "Appen ble installert og vil kj√∏re ledetekster i bakgrunnsprosesser p√• foresp√∏rsel.",
    "Model settings" : "Modellinnstillinger",
    "Choose the machine learning model to be used." : "Velg maskinl√¶ringsmodellen som skal brukes.",
    "Recommended" : "Anbefalt",
    "Bilingual: English/German" : "Tospr√•klig: Engelsk/Tysk",
    "Extended context length of 8k tokens" : "Utvidet kontekstlengde p√• 8k tokens",
    "To download the machine learning model, you need to excecute the occ command line interface of Nextcloud on your server terminal with the following command:" : "For √• laste ned maskinl√¶ringsmodellen, m√• du utf√∏re occ-kommandolinjegrensesnittet til Nextcloud p√• serverterminalen din med f√∏lgende kommando:",
    "Inference settings" : "Inferensinnstillinger",
    "The number of threads to use for inference (more is faster)" : "Antall tr√•der som skal brukes til inferens (mer er raskere)",
    "Python" : "Python",
    "Checking Python" : "Sjekker Python",
    "Could not execute Python. You may need to set the path to a working executable manually." : "Kunne ikke utf√∏re python. Du m√• kanskje angi banen til en fungerende kj√∏rbar manuelt.",
    "Python executable executed successfully and setup works." : "Python kj√∏rbar utf√∏rt vellykket og oppsettet fungerer.",
    "If Python is not found automatically on your system for some reason you can set the path to the Python executable here. If you change this value, make sure to run occ maintenance:repair afterwards." : "Hvis Python ikke blir funnet automatisk p√• systemet ditt av en eller annen grunn, kan du angi banen til den kj√∏rbare Python-filen her. Hvis du endrer denne verdien, m√• du s√∏rge for √• kj√∏re occ maintenance:repair etterp√•.",
    "Failed to load settings" : "Klarte ikke √• laste inn innstillinger",
    "Failed to save settings" : "Klarte ikke √• lagre innstillinger"
},
"nplurals=2; plural=(n != 1);");
