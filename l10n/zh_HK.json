{ "translations": {
    "Formalize" : "正式化",
    "Rephrase the text to be more formal and polite instead of casual." : "將文字改寫得更正式與禮貌，而非隨意。",
    "Simplify" : "簡化",
    "Make the text easier to understand." : "讓文字更容易理解。",
    "Local Large language model" : "近端大型語言模型",
    "TextProcessing provider using a Large Language Model that runs locally on CPU" : "使用大型語言模型的文字處理提供者，該模型在 CPU 上本機執行",
    "A TextProcessing provider Large Language Model that runs locally on CPU\n\nThe models run completely on your machine. No private data leaves your servers.\n\nAfter installing this app you will need to run\n\n    occ llm:download-model\n\nModels:\n\n* Llama 2 by Meta\n  * Languages: English\n  * [LLAMA 2 Community License](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* GPT4All Falcon by Nomic AI\n  * Languages: English\n  * [Apache License 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\nRequirements:\n\n* x86 CPU\n* GNU lib C (musl is not supported)\n* Python 3.10+  (including python-venv)\n\n#### Nextcloud All-in-One:\nWith Nextcloud AIO, this app is not going to work because AIO uses musl. However you can use [this community container](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai) as replacement for this app.\n\n## Ethical AI Rating \"Llama 2\" model\n### Rating: 🟡\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the model’s performance and CO2 usage.\n\n## Ethical AI Rating for \"GPT4All Falcon\" model\n### Rating: 🟢\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n* the training data is freely available, making it possible to check or correct for bias or optimise the performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/)." : "在 CPU 上本機執行的大型語言模型文字處理提供者\n\n這些模型完全在您的機器上執行。任何私人資料都不會離開您的伺服器。\n\n安裝此應用程式後，您必須執行\n\nocc llm:download-model\n\n模型：\n\n* Meta 製作的 Llama 2\n * 語言：英文\n * [LLAMA 2 社群授權條款](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* Nomic AI 的 GPT4All Falcon\n * 語言：英文\n * [Apache 授權條款 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\n系統需求：\n\n* x86 CPU\n* GNU lib C（不支援 musl）\n* Python 3.10+（包含 python-venv）\n\n#### Nextcloud All-in-One：\n使用 Nextcloud AIO 時，此應用程式無法運作，因為 AIO 使用 musl。不過，您可以使用[此社群容器](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai)作為此應用程式的替代品。\n\n## 「Llama 2」模型的道德人工智慧評分\n### 評分：🟡\n\n優點：\n* 此模型的訓練與推理軟體是開放原始碼的\n* 經過訓​​練的模型是免費提供的，因此可以在本機執行\n\n缺點：\n\n* 訓練資料並非免費提供，這限制了第三方檢查與糾正偏差或改善模型效能與二氧化碳使用的能力。\n\n## 「GPT4All Falcon」模型的道德人工智慧評分\n### 評分：🟢\n\n優點：\n* 此模型的訓練與推理軟體是開放原始碼的\n* 經過訓​​練的模型是免費提供的，因此可以在本機執行\n* 訓練資料免費提供，可以檢查或糾正偏差或改善效能與二氧化碳的使用。\n\n[在我們的部落格中](https://nextcloud.com/blog/nextcloud-ethical-ai- rating/)取得更多關於 Nextcloud 道德 AI 評分的資訊。",
    "Status" : "狀態",
    "Machine learning model has been downloaded successfully." : "已成功下載機器學習模型。",
    "The machine learning model still needs to be downloaded (see below)." : "機器學習模型仍需下載（見下方）。",
    "Could not execute python. You may need to set the path to a working executable manually. (See below.)" : "無法執行Python。 您可能需要人手設置正常運行的可執行檔案的路徑。（見下文）",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "背景作業並未透過 cron 執行。此應用程式需要背景作業透過 cron 執行。",
    "The app was installed successfully and will run prompts in background processes on request." : "應用程式已成功安裝，並將根據要求在背景處理程序中執行提示。",
    "Model settings" : "模型設定",
    "Choose the machine learning model to be used." : "選擇要使用的機器學習模型。",
    "Llama2 7B (Recommended)" : "Llama2 7B（推薦）",
    "GPT4All Falcon" : "GPT4All Falcon",
    "To download the machine learning model, you need to excecute the occ command line interface of Nextcloud on your server terminal with the following command:" : "要下載機器學習模型，您必須在您的伺服器終端機上使用 Nextcloud 的 occ 命令列介面執行以下指令：",
    "Inference settings" : "推理設置",
    "The number of threads to use for inference (more is faster)" : "用於推理的線程數（越多速度越快）",
    "Python" : "Python",
    "Checking Python" : "正在檢查 Python",
    "Could not execute Python. You may need to set the path to a working executable manually." : "無法執行Python。 您可能需要人手設置正常運行的可執行檔案的路徑。",
    "Python executable executed successfully and setup works." : "Python 可執行檔案已成功執行並且安裝程序有效。",
    "If Python is not found automatically on your system for some reason you can set the path to the Python executable here. If you change this value, make sure to run occ maintenance:repair afterwards." : "如果由於某種原因未在您的系統上自動找到 Python，您可以在此處設置 Python 可執行檔案的路徑。 如果更改此值，請確保隨後運行 occ Maintenance:repair。",
    "Failed to load settings" : "載入設定失敗",
    "Failed to save settings" : "設定儲存失敗"
},"pluralForm" :"nplurals=1; plural=0;"
}