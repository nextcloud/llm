OC.L10N.register(
    "llm",
    {
    "Formalize" : "Formalizar",
    "Rephrase the text to be more formal and polite instead of casual." : "Reformular o texto para que sexa m√°is formal e educado no canto de casual.",
    "Simplify" : "Simplificar",
    "Make the text easier to understand." : "Facilitar a comprensi√≥n do texto.",
    "Local Large language model" : "Gran modelo ling√º√≠stico local",
    "TextProcessing provider using a Large Language Model that runs locally on CPU" : "Fornecedor de procesamento de texto que utiliza o gran modelo ling√º√≠stico que se executa localmente na CPU",
    "A TextProcessing provider Large Language Model that runs locally on CPU\n\nThe models run completely on your machine. No private data leaves your servers.\n\nAfter installing this app you will need to run\n\n    occ llm:download-model\n\nModels:\n\n* Llama 2 by Meta\n  * Languages: English\n  * [LLAMA 2 Community License](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* GPT4All Falcon by Nomic AI\n  * Languages: English\n  * [Apache License 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\nRequirements:\n\n* x86 CPU\n* GNU lib C (musl is not supported)\n* Python 3.10+  (including python-venv)\n\n#### Nextcloud All-in-One:\nWith Nextcloud AIO, this app is not going to work because AIO uses musl. However you can use [this community container](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai) as replacement for this app.\n\n## Ethical AI Rating \"Llama 2\" model\n### Rating: üü°\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n\nNegative:\n\n* the training data is not freely available, limiting the ability of external parties to check and correct for bias or optimise the model‚Äôs performance and CO2 usage.\n\n## Ethical AI Rating for \"GPT4All Falcon\" model\n### Rating: üü¢\n\nPositive:\n* the software for training and inference of this model is open source\n* the trained model is freely available, and thus can be run on-premises\n* the training data is freely available, making it possible to check or correct for bias or optimise the performance and CO2 usage.\n\nLearn more about the Nextcloud Ethical AI Rating [in our blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/)." : "Un Gran modelo ling√º√≠stico do provedor de TextProcessing que se executa localmente na CPU\n\nOs modelos funcionan completamente na s√∫a m√°quina. Ning√∫n dato privado sae dos seus servidores.\n\nAp√≥s instalar esta aplicaci√≥n, ter√° que executar\n\n    occ llm:download-model\n\nModelos:\n\n* Llama 2 de Meta\n  *Idiomas: Ingl√©s\n  *[Licenza comunitaria LLAMA 2](https://download.nextcloud.com/server/apps/llm/llama-2-7b-chat-ggml/LICENSE)\n* GPT4All Falcon de Nomic AI\n  *Idiomas: Ingles\n  *[Licenza Apache 2.0](https://download.nextcloud.com/server/apps/llm/LICENSE)\nRequisitos:\n\n* CPU x86\n* GNU lib C (musl non √© compatible)\n* Python 3.10+ (inclu√≠ndo python-venv)\n\n#### Nextcloud All-in-One:\nCon Nextcloud AIO, esta aplicaci√≥n non vai funcionar porque AIO usa musl. Non obstante, pode usar [este contedor comunitario](https://github.com/nextcloud/all-in-one/tree/main/community-containers/local-ai) como substituto desta aplicaci√≥n.\n\n## Avaliaci√≥n √©tica da IA para o ‚Äã‚Äãmodelo ¬´Llama 2¬ª\n### Avaliaci√≥n: üü°\n\nPositiva:\n* O software para adestramento e inferencia deste modelo √© de c√≥digo aberto\n* O modelo adestrado est√° dispo√±√≠bel de xeito libre e, polo tanto, p√≥dese executar en instalaci√≥ns\n\nNegativa:\n\n* Os datos de adestramento non est√°n dispo√±√≠beis de xeito libre, o que limita a capacidade de partes externas para comprobar e corrixir nesgos ou optimizar o rendemento do modelo e o uso de CO2.\n\n## Avaliaci√≥n √©tica da IA para o modelo ¬´GPT4All Falcon¬ª.\n### Avaliaci√≥n: üü¢\n\nPositiva:\n* O software para adestramento e inferencia deste modelo √© de c√≥digo aberto\n* O modelo adestrado est√° dispo√±√≠bel de xeito libre e, polo tanto, p√≥dese executar en instalaci√≥ns\n* Os datos de adestramento est√°n dispo√±√≠beis de xeito libre, o que permite comprobar e corrixir nesgos ou optimizar o rendemento do modelo e o uso de CO2.\n\nObte√±a m√°is informaci√≥n sobre a avaliaci√≥n de IA √âtica de Nextcloud [no noso blog](https://nextcloud.com/blog/nextcloud-ethical-ai-rating/).",
    "Status" : "Estado",
    "Machine learning model has been downloaded successfully." : "O modelo de aprendizaxe autom√°tica foi descargado correctamente.",
    "The machine learning model still needs to be downloaded (see below)." : "A√≠nda hai que descargar o modelo de aprendizaxe autom√°tica. (vexa embaixo.)",
    "Could not execute python. You may need to set the path to a working executable manually. (See below.)" : "Non foi pos√≠bel executar Python. Quizais necesite estabelecer manualmente a ruta a un execut√°bel que funcione. (vexa embaixo.)",
    "Background Jobs are not executed via cron. This app requires background jobs to be executed via cron." : "Os traballos en segundo plano non se executan mediante cron. Esta aplicaci√≥n precisa que se executen traballos en segundo plano mediante cron.",
    "The app was installed successfully and will run prompts in background processes on request." : "A aplicaci√≥n foi instalada correctamente e executar√° solicitudes en procesos en segundo plano cando o solicite.",
    "Model settings" : "Axustes do modelo",
    "Choose the machine learning model to be used." : "Escolla o modelo de aprendizaxe autom√°tica que se utilizar√°.",
    "Recommended" : "Recomendado",
    "To download the machine learning model, you need to excecute the occ command line interface of Nextcloud on your server terminal with the following command:" : "Para descargar o modelo de aprendizaxe autom√°tica, debe executar a interface de li√±a de ordes occ de Nextcloud no terminal do seu servidor coa seguinte orde:",
    "Inference settings" : "Axustes de inferencia",
    "The number of threads to use for inference (more is faster)" : "O n√∫mero de f√≠os que se van usar para a inferencia (m√°is √© m√°is r√°pido)",
    "Python" : "Python",
    "Checking Python" : "Comprobaci√≥n de Python",
    "Could not execute Python. You may need to set the path to a working executable manually." : "Non foi pos√≠bel executar Python. Quizais necesite estabelecer manualmente a ruta a un execut√°bel que funcione.",
    "Python executable executed successfully and setup works." : "O execut√°bel de Python executouse con √©xito e a configuraci√≥n funciona.",
    "If Python is not found automatically on your system for some reason you can set the path to the Python executable here. If you change this value, make sure to run occ maintenance:repair afterwards." : "Se non se atopa automaticamente Python no seu sistema por alg√∫n motivo, pode estabelecer aqu√≠ unha ruta ao execut√°bel de Python. Se cambia este valor, aseg√∫rese de executar occ maintenance:repair ap√≥s.",
    "Failed to load settings" : "Produciuse un fallo ao cargar os axustes",
    "Failed to save settings" : "Produciuse un fallo ao gardar os axustes"
},
"nplurals=2; plural=(n != 1);");
